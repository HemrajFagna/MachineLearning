{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ad31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = [ [1,2], [3,5], [2,4], [7,8], [8,11], [9,10] ]\n",
    "\n",
    "clf = KMeans(n_clusters = 2)\n",
    "clf.fit(X)\n",
    "centroids = clf.cluster_centers_\n",
    "labels = clf.labels_\n",
    "\n",
    "colors = 10*[\"g.\",\"b.\",\"r.\",\"k.\",\"c.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], colors[labels[i]], markersize= 25)\n",
    "    \n",
    "plt.scatter(centroids[:,0], centroids[:,1], marker = 'x', s= 150)    \n",
    "plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7043544690603514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Applying Clustering on Titanic dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('ggplot')\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"C:/Users/Dell/Desktop/Python/titanic.xls\")\n",
    "df.drop(['body','name'],1, inplace= True)\n",
    "df.convert_objects(convert_numeric=True)\n",
    "df.fillna(0, inplace=True)\n",
    "#df.head()\n",
    "\n",
    "def handle_non_numeric_data(df):\n",
    "    columns = df.columns.values\n",
    "    for column in columns:\n",
    "        text_digit_vals = { }\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "        \n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            column_content = df[column].values.tolist()\n",
    "            unique_elements = set(column_content)\n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x += 1\n",
    "        \n",
    "            df[column] = list(map(convert_to_int, df[column]))\n",
    "    return df\n",
    "\n",
    "\n",
    "df = handle_non_numeric_data(df)\n",
    "#df[:50]\n",
    "\n",
    "X = np.array(df.drop(['survived'],1).astype(float))\n",
    "X = preprocessing.scale(X) # without this accu is 50%\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = KMeans(n_clusters=2)\n",
    "clf.fit(X)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction == y[i]:\n",
    "        correct += 1\n",
    "print(correct/ len(X)) # Accu  30 or 70 as labels get swaped in clusters       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pclass  survived     sex      age  sibsp  parch  ticket      fare    cabin  \\\n",
      "0       1         1  female  29.0000      0      0   24160  211.3375       B5   \n",
      "1       1         1    male   0.9167      1      2  113781  151.5500  C22 C26   \n",
      "2       1         0  female   2.0000      1      2  113781  151.5500  C22 C26   \n",
      "3       1         0    male  30.0000      1      2  113781  151.5500  C22 C26   \n",
      "4       1         0  female  25.0000      1      2  113781  151.5500  C22 C26   \n",
      "\n",
      "  embarked boat                        home.dest  \n",
      "0        S    2                     St Louis, MO  \n",
      "1        S   11  Montreal, PQ / Chesterville, ON  \n",
      "2        S  NaN  Montreal, PQ / Chesterville, ON  \n",
      "3        S  NaN  Montreal, PQ / Chesterville, ON  \n",
      "4        S  NaN  Montreal, PQ / Chesterville, ON  \n",
      "   pclass  survived  sex      age  sibsp  parch  ticket      fare  cabin  \\\n",
      "0       1         1    0  29.0000      0      0     736  211.3375     97   \n",
      "1       1         1    1   0.9167      1      2     503  151.5500     34   \n",
      "2       1         0    0   2.0000      1      2     503  151.5500     34   \n",
      "3       1         0    1  30.0000      1      2     503  151.5500     34   \n",
      "4       1         0    0  25.0000      1      2     503  151.5500     34   \n",
      "\n",
      "   embarked  boat  home.dest  \n",
      "0         0     1        101  \n",
      "1         0    23         71  \n",
      "2         0     0         71  \n",
      "3         0     0         71  \n",
      "4         0     0         71  \n",
      "0.41787624140565316\n"
     ]
    }
   ],
   "source": [
    "# implementing our own KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation\n",
    "import pandas as pd\n",
    "\n",
    "##X = np.array([[1, 2],\n",
    "##              [1.5, 1.8],\n",
    "##              [5, 8],\n",
    "##              [8, 8],\n",
    "##              [1, 0.6],\n",
    "##              [9, 11]])\n",
    "##\n",
    "##\n",
    "##colors = ['r','g','b','c','k','o','y']\n",
    "\n",
    "\n",
    "\n",
    "class K_Means:\n",
    "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
    "        self.k = k\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def fit(self,data):\n",
    "\n",
    "        self.centroids = {}\n",
    "\n",
    "        for i in range(self.k):\n",
    "            self.centroids[i] = data[i]\n",
    "\n",
    "        for i in range(self.max_iter):\n",
    "            self.classifications = {}\n",
    "\n",
    "            for i in range(self.k):\n",
    "                self.classifications[i] = []\n",
    "\n",
    "            for featureset in X:\n",
    "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
    "                classification = distances.index(min(distances))\n",
    "                self.classifications[classification].append(featureset)\n",
    "\n",
    "            prev_centroids = dict(self.centroids)\n",
    "\n",
    "            for classification in self.classifications:\n",
    "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
    "\n",
    "            optimized = True\n",
    "\n",
    "            for c in self.centroids:\n",
    "                original_centroid = prev_centroids[c]\n",
    "                current_centroid = self.centroids[c]\n",
    "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
    "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
    "                    optimized = False\n",
    "\n",
    "            if optimized:\n",
    "                break\n",
    "\n",
    "    def predict(self,data):\n",
    "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
    "        classification = distances.index(min(distances))\n",
    "        return classification\n",
    "\n",
    "\n",
    "# https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls\n",
    "df = pd.read_excel(\"C:/Users/Dell/Desktop/Python/titanic.xls\")\n",
    "df.drop(['body','name'], 1, inplace=True)\n",
    "#df.convert_objects(convert_numeric=True)\n",
    "print(df.head())\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "def handle_non_numerical_data(df):\n",
    "    \n",
    "    # handling non-numerical data: must convert.\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        #print(column,df[column].dtype)\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            \n",
    "            column_contents = df[column].values.tolist()\n",
    "            #finding just the uniques\n",
    "            unique_elements = set(column_contents)\n",
    "            # great, found them. \n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    # creating dict that contains new\n",
    "                    # id per unique string\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "            # now we map the new \"id\" vlaue\n",
    "            # to replace the string. \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "\n",
    "    return df\n",
    "\n",
    "df = handle_non_numerical_data(df)\n",
    "print(df.head())\n",
    "\n",
    "# add/remove features just to see impact they have.\n",
    "#df.drop(['ticket','home.dest'], 1, inplace=True)\n",
    "\n",
    "\n",
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "#X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "clf = K_Means()\n",
    "clf.fit(X)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = clf.predict(predict_me)\n",
    "    if prediction == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "\n",
    "print(correct/len(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
