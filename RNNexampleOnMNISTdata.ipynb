{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#from tensorflow.python.ops import rnn, rnn_cell\n",
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In machine learning, an epoch is a full iteration over samples. Here, we are restricting the model\n",
    "to 10 complete epochs or cycles of the algorithm running through the dataset.\n",
    "\n",
    "The batch variable determines the amount of data being fed to the algorithm\n",
    "at any given time, in this case, 100 images.\n",
    "'''\n",
    "n_classes = 10\n",
    "batch_size = 128\n",
    "hm_epochs = 3\n",
    "\n",
    "chunk_size = 28 #28 cols\n",
    "n_chunks = 28 #28 rows\n",
    "rnn_size = 128\n",
    "\n",
    "# Height x Weight matrix\n",
    "# None represents batch size\n",
    "\n",
    "'''\n",
    "The method tf.placeholder allows us to create variables that act as nodes holding the data.\n",
    "Here, x is a 2-dimensionall array holding the MNIST images, with none implying the batch size\n",
    "(which can be of any size) and 784 being a single 28×28 image. y is the target output class that\n",
    "consists of a 2-dimensional array of 10 classes (denoting the numbers 0-9) that identify what digit is stored in each image.\n",
    "\n",
    "'''\n",
    "x = tf.placeholder('float',[None, n_chunks, chunk_size])\n",
    "y = tf.placeholder('float',[None,n_classes]) #label for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_neural_network(x):\n",
    "    layer = {'weights': tf.Variable(tf.random_normal([rnn_size, n_classes])),\n",
    "                      'biases': tf.Variable(tf.random_normal([n_classes]))}\n",
    "    \n",
    "    x = tf.transpose(x,[1,0,2])\n",
    "    x = tf.reshape(x, [-1, chunk_size])\n",
    "    x = tf.split(x, n_chunks, 0)\n",
    "    \n",
    "    lstm_cell = rnn.BasicLSTMCell(rnn_size)\n",
    "    \n",
    "    '''\n",
    "    The output generated by static_rnn is a list of tensors of shape [batch_size,num_units].\n",
    "    The length of the list is number of time steps through which network is unrolled\n",
    "    i.e. one output tensor for each time step\n",
    "    \n",
    "    '''\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype = tf.float32)\n",
    "    \n",
    "    output = tf.matmul(outputs[-1], layer['weights']) + layer['biases']\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We will be using a simple softmax model to implement our network. Softmax is a generalization of logistic regression,\n",
    "usually used in the final layer of a network. It is useful because it helps in multi-classification models where a given\n",
    "output can be a list of many different things.\n",
    "It provides values between 0 to 1 that in addition give you the probability of the output belonging to a particular class. \n",
    "'''\n",
    "\n",
    "def train_neural_network(x):\n",
    "    prediction = recurrent_neural_network(x)\n",
    "\n",
    "    ''' This is the cost function of the model – a cost function is a difference between the predicted value and\n",
    "    the actual value that we are trying to minimize to improve the accuracy of the model'''\n",
    "    \n",
    "    cost  = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction,labels = y)) #loss\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(hm_epochs):\n",
    "            epoch_loss = 0\n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                epoch_x, epoch_y = mnist.train.next_batch(batch_size)\n",
    "                epoch_x = epoch_x.reshape((batch_size, n_chunks, chunk_size))\n",
    "                _,c = sess.run([optimizer,cost], feed_dict= {x: epoch_x, y: epoch_y}) #c is loss\n",
    "                \n",
    "                epoch_loss += c\n",
    "            print('Epoch ',epoch+1,' completed out of ',hm_epochs,', loss ',epoch_loss)\n",
    "            \n",
    "        correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y,1))\n",
    "        accuracy  = tf.reduce_mean(tf.cast(correct,'float'))\n",
    "        \n",
    "        print('Accuracy: ',accuracy.eval({ x: mnist.test.images.reshape((-1, n_chunks, chunk_size)), y: mnist.test.labels }))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hm_epochs = 4, accuracy = 93%\n",
    "# hm_epochs = 10, accuracy = 95.14%\n",
    "#hm_epochs = 15, accuracy = 95.54%\n",
    "#hm_epochs = 10, accuracy = 98.29% with RNN\n",
    "#hm_epochs = 3, accuracy = 97.38% with RNN\n",
    "#tf.reset_default_graph() , try to add code in single file \n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
